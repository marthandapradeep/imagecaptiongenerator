{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "import concurrent.futures\n",
    "import collections\n",
    "import dataclasses\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flickr8k(path='flickr8k'):\n",
    "  path = pathlib.Path(path)\n",
    "\n",
    "  if len(list(path.rglob('*'))) < 16197:\n",
    "    tf.keras.utils.get_file(\n",
    "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip',\n",
    "        cache_dir='.',\n",
    "        cache_subdir=path,\n",
    "        extract=True)\n",
    "    tf.keras.utils.get_file(\n",
    "        origin='https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip',\n",
    "        cache_dir='.',\n",
    "        cache_subdir=path,\n",
    "        extract=True)\n",
    "    \n",
    "  captions = (path/\"Flickr8k.token.txt\").read_text().splitlines()\n",
    "  captions = (line.split('\\t') for line in captions)\n",
    "  captions = ((fname.split('#')[0], caption) for (fname, caption) in captions)\n",
    "\n",
    "  cap_dict = collections.defaultdict(list)\n",
    "  for fname, cap in captions:\n",
    "    cap_dict[fname].append(cap)\n",
    "\n",
    "  train_files = (path/'Flickr_8k.trainImages.txt').read_text().splitlines()\n",
    "  train_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in train_files]\n",
    "\n",
    "  test_files = (path/'Flickr_8k.testImages.txt').read_text().splitlines()\n",
    "  test_captions = [(str(path/'Flicker8k_Dataset'/fname), cap_dict[fname]) for fname in test_files]\n",
    "\n",
    "  train_ds = tf.data.experimental.from_list(train_captions)\n",
    "  test_ds = tf.data.experimental.from_list(test_captions)\n",
    "\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptual_captions(*, data_dir=\"conceptual_captions\", num_train, num_val):\n",
    "  def iter_index(index_path):\n",
    "    with open(index_path) as f:\n",
    "      for line in f:\n",
    "        caption, url = line.strip().split('\\t')\n",
    "        yield caption, url\n",
    "\n",
    "  def download_image_urls(data_dir, urls):\n",
    "    ex = concurrent.futures.ThreadPoolExecutor(max_workers=100)\n",
    "    def save_image(url):\n",
    "      hash = hashlib.sha1(url.encode())\n",
    "      # Name the files after the hash of the URL.\n",
    "      file_path = data_dir/f'{hash.hexdigest()}.jpeg'\n",
    "      if file_path.exists():\n",
    "        # Only download each file once.\n",
    "        return file_path\n",
    "\n",
    "      try:\n",
    "        result = requests.get(url, timeout=5)\n",
    "      except Exception:\n",
    "        file_path = None\n",
    "      else:\n",
    "        file_path.write_bytes(result.content)\n",
    "      return file_path\n",
    "    \n",
    "    result = []\n",
    "    out_paths = ex.map(save_image, urls)\n",
    "    for file_path in tqdm.tqdm(out_paths, total=len(urls)):\n",
    "      result.append(file_path)\n",
    "\n",
    "    return result\n",
    "\n",
    "  def ds_from_index_file(index_path, data_dir, count):\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    index = list(itertools.islice(iter_index(index_path), count))\n",
    "    captions = [caption for caption, url in index]\n",
    "    urls = [url for caption, url in index]\n",
    "\n",
    "    paths = download_image_urls(data_dir, urls)\n",
    "\n",
    "    new_captions = []\n",
    "    new_paths = []\n",
    "    for cap, path in zip(captions, paths):\n",
    "      if path is None:\n",
    "        # Download failed, so skip this pair.\n",
    "        continue\n",
    "      new_captions.append(cap)\n",
    "      new_paths.append(path)\n",
    "    \n",
    "    new_paths = [str(p) for p in new_paths]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((new_paths, new_captions))\n",
    "    ds = ds.map(lambda path,cap: (path, cap[tf.newaxis])) # 1 caption per image\n",
    "    return ds\n",
    "\n",
    "  data_dir = pathlib.Path(data_dir)\n",
    "  train_index_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/gcc-data/Train/GCC-training.tsv',\n",
    "    cache_subdir=data_dir,\n",
    "    cache_dir='.')\n",
    "  \n",
    "  val_index_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/gcc-data/Validation/GCC-1.1.0-Validation.tsv',\n",
    "    cache_subdir=data_dir,\n",
    "    cache_dir='.')\n",
    "  \n",
    "  train_raw = ds_from_index_file(train_index_path, data_dir=data_dir/'train', count=num_train)\n",
    "  test_raw = ds_from_index_file(val_index_path, data_dir=data_dir/'val', count=num_val)\n",
    "\n",
    "  return train_raw, test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
      "1115419746/1115419746 [==============================] - 240s 0us/step\n",
      "Downloading data from https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
      "2340801/2340801 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "choose = 'flickr8k'\n",
    "\n",
    "if choose == 'flickr8k':\n",
    "  train_raw, test_raw = flickr8k()\n",
    "else:\n",
    "  train_raw, test_raw = conceptual_captions(num_train=10000, num_val=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(5,), dtype=tf.string, name=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'flickr8k\\\\Flicker8k_Dataset\\\\2513260012_03d33305cf.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'A black dog is running after a white dog in the snow .'\n",
      " b'Black dog chasing brown dog through snow'\n",
      " b'Two dogs chase each other across the snowy ground .'\n",
      " b'Two dogs play together in the snow .'\n",
      " b'Two dogs running through a low lying body of water .'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for ex_path, ex_captions in train_raw.take(1):\n",
    "  print(ex_path)\n",
    "  print(ex_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE=(224, 224, 3)\n",
    "mobilenet = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    include_top=False,\n",
    "    include_preprocessing=True)\n",
    "mobilenet.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMAGE_SHAPE[:-1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 7, 7, 576)\n"
     ]
    }
   ],
   "source": [
    "test_img_batch = load_image(ex_path)[tf.newaxis, :]\n",
    "\n",
    "print(test_img_batch.shape)\n",
    "print(mobilenet(test_img_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(s):\n",
    "  s = tf.strings.lower(s)\n",
    "  s = tf.strings.regex_replace(s, f'[{re.escape(string.punctuation)}]', '')\n",
    "  s = tf.strings.join(['[START]', s, '[END]'], separator=' ')\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the top 5000 words for a vocabulary.\n",
    "vocabulary_size = 5000\n",
    "tokenizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    standardize=standardize,\n",
    "    ragged=True)\n",
    "# Learn the vocabulary from the caption data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.adapt(train_raw.map(lambda fp,txt: txt).unbatch().batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'a', '[START]', '[END]', 'in', 'the', 'on', 'is', 'and']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[3, 2, 655, 5, 2, 97, 4], [3, 2, 1937, 10, 4]]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tokenizer([['a cat in a hat'], ['a robot dog']])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create mappings for words to indices and indices to words.\n",
    "word_to_index = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary())\n",
    "index_to_word = tf.keras.layers.StringLookup(\n",
    "    mask_token=\"\",\n",
    "    vocabulary=tokenizer.get_vocabulary(),\n",
    "    invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'[START]', b'a', b'cat', b'in', b'a', b'hat', b'[END]'],\n",
       " [b'[START]', b'a', b'robot', b'dog', b'[END]']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = index_to_word(t)\n",
    "w.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'[START] a cat in a hat [END]', b'[START] a robot dog [END]'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(w, separator=' ', axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_shapes(images, captions):\n",
    "  caption_shape = einops.parse_shape(captions, 'b c')\n",
    "  captions = einops.rearrange(captions, 'b c -> (b c)')\n",
    "  images = einops.repeat(\n",
    "      images, 'b ... -> (b c) ...',\n",
    "      c = caption_shape['c'])\n",
    "  return images, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image paths: (32,)\n",
      "captions: (32, 5)\n",
      "\n",
      "image_paths: (160,)\n",
      "captions: (160,)\n"
     ]
    }
   ],
   "source": [
    "for ex_paths, ex_captions in train_raw.batch(32).take(1):\n",
    "  break\n",
    "\n",
    "print('image paths:', ex_paths.shape)\n",
    "print('captions:', ex_captions.shape)\n",
    "print()\n",
    "\n",
    "ex_paths, ex_captions = match_shapes(images=ex_paths, captions=ex_captions)\n",
    "\n",
    "print('image_paths:', ex_paths.shape)\n",
    "print('captions:', ex_captions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_txt(imgs, txts):\n",
    "  tokens = tokenizer(txts)\n",
    "\n",
    "  input_tokens = tokens[..., :-1]\n",
    "  label_tokens = tokens[..., 1:]\n",
    "  return (imgs, input_tokens), label_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds, tokenizer, batch_size=32, shuffle_buffer=1000):\n",
    "  # Load the images and make batches.\n",
    "  ds = (ds\n",
    "        .shuffle(10000)\n",
    "        .map(lambda path, caption: (load_image(path), caption))\n",
    "        .apply(tf.data.experimental.ignore_errors())\n",
    "        .batch(batch_size))\n",
    "\n",
    "  def to_tensor(inputs, labels):\n",
    "    (images, in_tok), out_tok = inputs, labels\n",
    "    return (images, in_tok.to_tensor()), out_tok.to_tensor()\n",
    "\n",
    "  return (ds\n",
    "          .map(match_shapes, tf.data.AUTOTUNE)\n",
    "          .unbatch()\n",
    "          .shuffle(shuffle_buffer)\n",
    "          .batch(batch_size)\n",
    "          .map(prepare_txt, tf.data.AUTOTUNE)\n",
    "          .map(to_tensor, tf.data.AUTOTUNE)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rspra\\AppData\\Local\\Temp\\ipykernel_10460\\1004139779.py:6: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, None), dtype=tf.int64, name=None)),\n",
       " TensorSpec(shape=(None, None), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = prepare_dataset(train_raw, tokenizer)\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, None), dtype=tf.int64, name=None)),\n",
       " TensorSpec(shape=(None, None), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = prepare_dataset(test_raw, tokenizer)\n",
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(ds, save_path, image_model, tokenizer, shards=10, batch_size=32):\n",
    "  # Load the images and make batches.\n",
    "  ds = (ds\n",
    "        .map(lambda path, caption: (load_image(path), caption))\n",
    "        .apply(tf.data.experimental.ignore_errors())\n",
    "        .batch(batch_size))\n",
    "\n",
    "  # Run the feature extractor on each batch\n",
    "  # Don't do this in a .map, because tf.data runs on the CPU. \n",
    "  def gen():\n",
    "    for (images, captions) in tqdm.tqdm(ds): \n",
    "      feature_maps = image_model(images)\n",
    "\n",
    "      feature_maps, captions = match_shapes(feature_maps, captions)\n",
    "      yield feature_maps, captions\n",
    "\n",
    "  # Wrap the generator in a new tf.data.Dataset.\n",
    "  new_ds = tf.data.Dataset.from_generator(\n",
    "      gen,\n",
    "      output_signature=(\n",
    "          tf.TensorSpec(shape=image_model.output_shape),\n",
    "          tf.TensorSpec(shape=(None,), dtype=tf.string)))\n",
    "\n",
    "  # Apply the tokenization \n",
    "  new_ds = (new_ds\n",
    "            .map(prepare_txt, tf.data.AUTOTUNE)\n",
    "            .unbatch()\n",
    "            .shuffle(1000))\n",
    "\n",
    "  # Save the dataset into shard files.\n",
    "  def shard_func(i, item):\n",
    "    return i % shards\n",
    "  new_ds.enumerate().save(save_path, shard_func=shard_func)\n",
    "\n",
    "def load_dataset(save_path, batch_size=32, shuffle=1000, cycle_length=2):\n",
    "  def custom_reader_func(datasets):\n",
    "    datasets = datasets.shuffle(1000)\n",
    "    return datasets.interleave(lambda x: x, cycle_length=cycle_length)\n",
    "  \n",
    "  ds = tf.data.Dataset.load(save_path, reader_func=custom_reader_func)\n",
    "\n",
    "  def drop_index(i, x):\n",
    "    return x\n",
    "\n",
    "  ds = (ds\n",
    "        .map(drop_index, tf.data.AUTOTUNE)\n",
    "        .shuffle(shuffle)\n",
    "        .padded_batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE))\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [02:50,  1.10it/s]\n",
      "32it [00:29,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dataset(train_raw, 'train_cache', mobilenet, tokenizer)\n",
    "save_dataset(test_raw, 'test_cache', mobilenet, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset('train_cache')\n",
    "test_ds = load_dataset('test_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 7, 7, 576), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, None), dtype=tf.int64, name=None)),\n",
       " TensorSpec(shape=(None, None), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7, 7, 576)\n",
      "(32, 16)\n",
      "(32, 16)\n"
     ]
    }
   ],
   "source": [
    "for (inputs, ex_labels) in train_ds.take(1):\n",
    "  (ex_img, ex_in_tok) = inputs\n",
    "\n",
    "print(ex_img.shape)\n",
    "print(ex_in_tok.shape)\n",
    "print(ex_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, max_length, depth):\n",
    "    super().__init__()\n",
    "    self.pos_embedding = tf.keras.layers.Embedding(input_dim=max_length, output_dim=depth)\n",
    "\n",
    "    self.token_embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=depth,\n",
    "        mask_zero=True)\n",
    "    \n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, seq):\n",
    "    seq = self.token_embedding(seq) # (batch, seq, depth)\n",
    "\n",
    "    x = tf.range(tf.shape(seq)[1])  # (seq)\n",
    "    x = x[tf.newaxis, :]  # (1, seq)\n",
    "    x = self.pos_embedding(x)  # (1, seq, depth)\n",
    "\n",
    "    return self.add([seq,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    # Use Add instead of + so the keras mask propagates through.\n",
    "    self.add = tf.keras.layers.Add() \n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "  \n",
    "  def call(self, x):\n",
    "    attn = self.mha(query=x, value=x,\n",
    "                    use_causal_mask=True)\n",
    "    x = self.add([x, attn])\n",
    "    return self.layernorm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self,**kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.add = tf.keras.layers.Add() \n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "  \n",
    "  def call(self, x, y, **kwargs):\n",
    "    attn, attention_scores = self.mha(\n",
    "             query=x, value=y,\n",
    "             return_attention_scores=True)\n",
    "    \n",
    "    self.last_attention_scores = attention_scores\n",
    "\n",
    "    x = self.add([x, attn])\n",
    "    return self.layernorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=2*units, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=units),\n",
    "        tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "    ])\n",
    "\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "  \n",
    "  def call(self, x):\n",
    "    x = x + self.seq(x)\n",
    "    return self.layernorm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, num_heads=1, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.self_attention = CausalSelfAttention(num_heads=num_heads,\n",
    "                                              key_dim=units,\n",
    "                                              dropout=dropout_rate)\n",
    "    self.cross_attention = CrossAttention(num_heads=num_heads,\n",
    "                                          key_dim=units,\n",
    "                                          dropout=dropout_rate)\n",
    "    self.ff = FeedForward(units=units, dropout_rate=dropout_rate)\n",
    "      \n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "    in_seq, out_seq = inputs\n",
    "\n",
    "    # Text input\n",
    "    out_seq = self.self_attention(out_seq)\n",
    "\n",
    "    out_seq = self.cross_attention(out_seq, in_seq)\n",
    "    \n",
    "    self.last_attention_scores = self.cross_attention.last_attention_scores\n",
    "\n",
    "    out_seq = self.ff(out_seq)\n",
    "\n",
    "    return out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class TokenOutput(tf.keras.layers.Layer):\n",
    "  def __init__(self, tokenizer, banned_tokens=(' ','[UNK]','[START]'),**kwargs):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(\n",
    "        units=tokenizer.vocabulary_size(), **kwargs)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.banned_tokens = banned_tokens\n",
    "\n",
    "    self.bias = None\n",
    "\n",
    "  def adapt(self, ds):\n",
    "    counts = collections.Counter()\n",
    "    vocab_dict = {name: id \n",
    "                  for id, name in enumerate(self.tokenizer.get_vocabulary())}\n",
    "\n",
    "    for tokens in tqdm.tqdm(ds):\n",
    "      counts.update(tokens.numpy().flatten())\n",
    "\n",
    "    counts_arr = np.zeros(shape=(self.tokenizer.vocabulary_size(),))\n",
    "    counts_arr[np.array(list(counts.keys()), dtype=np.int32)] = list(counts.values())\n",
    "\n",
    "    counts_arr = counts_arr[:]\n",
    "    for token in self.banned_tokens:\n",
    "      counts_arr[vocab_dict[token]] = 0\n",
    "\n",
    "    total = counts_arr.sum()\n",
    "    p = counts_arr/total\n",
    "    p[counts_arr==0] = 1.0\n",
    "    log_p = np.log(p)  # log(1) == 0\n",
    "\n",
    "    entropy = -(log_p*p).sum()\n",
    "\n",
    "    print()\n",
    "    print(f\"Uniform entropy: {np.log(self.tokenizer.vocabulary_size()):0.2f}\")\n",
    "    print(f\"Marginal entropy: {entropy:0.2f}\")\n",
    "\n",
    "    self.bias = log_p\n",
    "    self.bias[counts_arr==0] = -1e9\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.dense(x)\n",
    "    # TODO(b/250038731): Fix this.\n",
    "    # An Add layer doesn't work because of the different shapes.\n",
    "    # This clears the mask, that's okay because it prevents keras from rescaling\n",
    "    # the losses.\n",
    "    return x + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:14<00:00, 64.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform entropy: 8.52\n",
      "Marginal entropy: 5.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_layer = TokenOutput(tokenizer, banned_tokens=('','[UNK]','[START]'))\n",
    "# This might run a little faster if the dataset didn't also have to load the image data.\n",
    "output_layer.adapt(train_ds.map(lambda inputs, labels: labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Captioner(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def __init__(self, tokenizer, feature_extractor, output_layer, num_layers=1,\n",
    "               units=256, max_length=50, num_heads=1, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.feature_extractor = feature_extractor\n",
    "    self.tokenizer = tokenizer\n",
    "    self.word_to_index = tf.keras.layers.StringLookup(\n",
    "        mask_token=\"\",\n",
    "        vocabulary=tokenizer.get_vocabulary())\n",
    "    self.index_to_word = tf.keras.layers.StringLookup(\n",
    "        mask_token=\"\",\n",
    "        vocabulary=tokenizer.get_vocabulary(),\n",
    "        invert=True) \n",
    "\n",
    "    self.seq_embedding = SeqEmbedding(\n",
    "        vocab_size=tokenizer.vocabulary_size(),\n",
    "        depth=units,\n",
    "        max_length=max_length)\n",
    "\n",
    "    self.decoder_layers = [\n",
    "        DecoderLayer(units, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "        for n in range(num_layers)]\n",
    "\n",
    "    self.output_layer = output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "  @Captioner.add_method\n",
    "  def call(self, inputs):\n",
    "    image, txt = inputs\n",
    "\n",
    "    if image.shape[-1] == 3:\n",
    "      # Apply the feature-extractor, if you get an RGB image.\n",
    "      image = self.feature_extractor(image)\n",
    "    \n",
    "    # Flatten the feature map\n",
    "    image = einops.rearrange(image, 'b h w c -> b (h w) c')\n",
    "\n",
    "\n",
    "    if txt.dtype == tf.string:\n",
    "      # Apply the tokenizer if you get string inputs.\n",
    "      txt = tokenizer(txt)\n",
    "\n",
    "    txt = self.seq_embedding(txt)\n",
    "\n",
    "    # Look at the image\n",
    "    for dec_layer in self.decoder_layers:\n",
    "      txt = dec_layer(inputs=(image, txt))\n",
    "      \n",
    "    txt = self.output_layer(txt)\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Captioner(tokenizer, feature_extractor=mobilenet, output_layer=output_layer,\n",
    "                  units=256, dropout_rate=0.5, num_layers=2, num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = 'https://tensorflow.org/images/surf.jpg'\n",
    "image_path = tf.keras.utils.get_file('surf.jpg', origin=image_url)\n",
    "image = load_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Captioner.add_method\n",
    "def simple_gen(self, image, temperature=1):\n",
    "  initial = self.word_to_index([['[START]']]) # (batch, sequence)\n",
    "  img_features = self.feature_extractor(image[tf.newaxis, ...])\n",
    "\n",
    "  tokens = initial # (batch, sequence)\n",
    "  for n in range(50):\n",
    "    preds = self((img_features, tokens)).numpy()  # (batch, sequence, vocab)\n",
    "    preds = preds[:,-1, :]  #(batch, vocab)\n",
    "    if temperature==0:\n",
    "        next = tf.argmax(preds, axis=-1)[:, tf.newaxis]  # (batch, 1)\n",
    "    else:\n",
    "        next = tf.random.categorical(preds/temperature, num_samples=1)  # (batch, 1)\n",
    "    tokens = tf.concat([tokens, next], axis=1) # (batch, sequence) \n",
    "\n",
    "    if next[0] == self.word_to_index('[END]'):\n",
    "      break\n",
    "  words = index_to_word(tokens[0, 1:-1])\n",
    "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "  return result.numpy().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dog a from the in and in a water small a stop people neighborhood a in dancing boy red down a snow wears\n"
     ]
    }
   ],
   "source": [
    "for t in (0.0, 0.5, 1.0):\n",
    "  result = model.simple_gen(image, temperature=t)\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_loss(labels, preds):  \n",
    "  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, preds)\n",
    "\n",
    "  mask = (labels != 0) & (loss < 1e8) \n",
    "  mask = tf.cast(mask, loss.dtype)\n",
    "\n",
    "  loss = loss*mask\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "def masked_acc(labels, preds):\n",
    "  mask = tf.cast(labels!=0, tf.float32)\n",
    "  preds = tf.argmax(preds, axis=-1)\n",
    "  labels = tf.cast(labels, tf.int64)\n",
    "  match = tf.cast(preds == labels, mask.dtype)\n",
    "  acc = tf.reduce_sum(match*mask)/tf.reduce_sum(mask)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    image_url = 'https://tensorflow.org/images/surf.jpg'\n",
    "    image_path = tf.keras.utils.get_file('surf.jpg', origin=image_url)\n",
    "    self.image = load_image(image_path)\n",
    "\n",
    "  def on_epoch_end(self, epochs=None, logs=None):\n",
    "    print()\n",
    "    print()\n",
    "    for t in (0.0, 0.5, 1.0):\n",
    "      result = self.model.simple_gen(self.image, temperature=t)\n",
    "      print(result)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g = GenerateText()\n",
    "g.model = model\n",
    "g.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    GenerateText(),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=5, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "           loss=masked_loss,\n",
    "           metrics=[masked_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.9898 - masked_acc: 0.2003\n",
      "\n",
      "a man in a man in a man in a\n",
      "a man young in a is boy water\n",
      "dog woman are brown ice the wakeboarding out over a playing football\n",
      "\n",
      "100/100 [==============================] - 66s 596ms/step - loss: 4.9898 - masked_acc: 0.2003 - val_loss: 4.6774 - val_masked_acc: 0.2357\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.6078 - masked_acc: 0.2528\n",
      "\n",
      "a man in a red is in the water\n",
      "a young in a girl is running\n",
      "two four drops are are snowy wet the playing\n",
      "\n",
      "100/100 [==============================] - 59s 587ms/step - loss: 4.6078 - masked_acc: 0.2528 - val_loss: 4.3598 - val_masked_acc: 0.2701\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.3832 - masked_acc: 0.2780\n",
      "\n",
      "a man in a red water\n",
      "a young boy is standing on a water\n",
      "a outfits runs as children by water\n",
      "\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 4.3832 - masked_acc: 0.2780 - val_loss: 4.1823 - val_masked_acc: 0.2964\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.2829 - masked_acc: 0.2906\n",
      "\n",
      "a man in a red shirt is running in the water\n",
      "a man in a snow\n",
      "a young black with water on a edge jumps band\n",
      "\n",
      "100/100 [==============================] - 52s 521ms/step - loss: 4.2829 - masked_acc: 0.2906 - val_loss: 4.0314 - val_masked_acc: 0.3065\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.1136 - masked_acc: 0.3062\n",
      "\n",
      "a man in a red shirt is in the water\n",
      "a person in a red is in the background\n",
      "two motorcyclists on water mouth\n",
      "\n",
      "100/100 [==============================] - 52s 517ms/step - loss: 4.1136 - masked_acc: 0.3062 - val_loss: 4.0105 - val_masked_acc: 0.3091\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 4.0605 - masked_acc: 0.3125\n",
      "\n",
      "a man is in a water\n",
      "a man in a a child in the water\n",
      "a person is jumping on a yellow dirt swing into\n",
      "\n",
      "100/100 [==============================] - 52s 525ms/step - loss: 4.0605 - masked_acc: 0.3125 - val_loss: 3.8330 - val_masked_acc: 0.3249\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.9417 - masked_acc: 0.3234\n",
      "\n",
      "a man in a red shirt is running in the water\n",
      "a man is jumping the water\n",
      "the person doing a pink and man is squirted and a hat umbrellas silhouetted\n",
      "\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 3.9417 - masked_acc: 0.3234 - val_loss: 3.8518 - val_masked_acc: 0.3239\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8543 - masked_acc: 0.3299\n",
      "\n",
      "a man in a red shirt is standing in the water\n",
      "a man is jumping on a pool\n",
      "a man in green a tennis through the pool\n",
      "\n",
      "100/100 [==============================] - 60s 601ms/step - loss: 3.8543 - masked_acc: 0.3299 - val_loss: 3.7097 - val_masked_acc: 0.3367\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.8208 - masked_acc: 0.3337\n",
      "\n",
      "a man in a red shirt is jumping in the water\n",
      "a man is a pool while the water\n",
      "a man are snow in a wave\n",
      "\n",
      "100/100 [==============================] - 48s 479ms/step - loss: 3.8208 - masked_acc: 0.3337 - val_loss: 3.6864 - val_masked_acc: 0.3358\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.7413 - masked_acc: 0.3405\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a person is playing in a pool\n",
      "a man is riding a jumps in a bench in the ocean and black jeans in dog watches\n",
      "\n",
      "100/100 [==============================] - 48s 479ms/step - loss: 3.7413 - masked_acc: 0.3405 - val_loss: 3.5927 - val_masked_acc: 0.3397\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6508 - masked_acc: 0.3442\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a man is jumping into a pool\n",
      "a player playing in the water through restaurants\n",
      "\n",
      "100/100 [==============================] - 47s 472ms/step - loss: 3.6508 - masked_acc: 0.3442 - val_loss: 3.5550 - val_masked_acc: 0.3479\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.6379 - masked_acc: 0.3436\n",
      "\n",
      "a man in a red shirt is jumping in the water\n",
      "a black dog is throwing a water\n",
      "a man is murky the stick in his blue is five arms in it\n",
      "\n",
      "100/100 [==============================] - 66s 662ms/step - loss: 3.6379 - masked_acc: 0.3436 - val_loss: 3.4812 - val_masked_acc: 0.3508\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5830 - masked_acc: 0.3523\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a person in a blue jacket is running on the water\n",
      "a person in a large rides his blue player at a white house\n",
      "\n",
      "100/100 [==============================] - 77s 772ms/step - loss: 3.5830 - masked_acc: 0.3523 - val_loss: 3.4783 - val_masked_acc: 0.3516\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.5361 - masked_acc: 0.3550\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a man is in a swimming pool in the water\n",
      "a man in a white pool\n",
      "\n",
      "100/100 [==============================] - 52s 526ms/step - loss: 3.5361 - masked_acc: 0.3550 - val_loss: 3.4305 - val_masked_acc: 0.3538\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4980 - masked_acc: 0.3590\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man in a white shirt is in a water\n",
      "dog is running into the water\n",
      "\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 3.4980 - masked_acc: 0.3590 - val_loss: 3.4123 - val_masked_acc: 0.3549\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4761 - masked_acc: 0.3564\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man in a red shirt is sitting on a wave\n",
      "a girl is an retrieving a wave\n",
      "\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 3.4761 - masked_acc: 0.3564 - val_loss: 3.3779 - val_masked_acc: 0.3540\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.4546 - masked_acc: 0.3618\n",
      "\n",
      "a man in a blue shirt is jumping into the water\n",
      "a man in a blue shirt is jumping into a pool\n",
      "a basket of a small shirt is swimming back\n",
      "\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 3.4546 - masked_acc: 0.3618 - val_loss: 3.3810 - val_masked_acc: 0.3574\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3797 - masked_acc: 0.3688\n",
      "\n",
      "a man in a red shirt is jumping into the water\n",
      "a man in a red shirt is jumping on a wave\n",
      "a jr puppy jogs in the old fall\n",
      "\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 3.3797 - masked_acc: 0.3688 - val_loss: 3.3319 - val_masked_acc: 0.3608\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3385 - masked_acc: 0.3714\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a red shirt is riding a in a yellow pool\n",
      "a man in the black striped a child in his looks at their middle of water\n",
      "\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 3.3385 - masked_acc: 0.3714 - val_loss: 3.3254 - val_masked_acc: 0.3622\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.3153 - masked_acc: 0.3706\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a yellow blue pool\n",
      "a long collage in ocean water pool\n",
      "\n",
      "100/100 [==============================] - 53s 529ms/step - loss: 3.3153 - masked_acc: 0.3706 - val_loss: 3.2640 - val_masked_acc: 0.3626\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2959 - masked_acc: 0.3715\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a white shirt and blue is doing a wave\n",
      "a man in the the top church under a wave\n",
      "\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 3.2959 - masked_acc: 0.3715 - val_loss: 3.2357 - val_masked_acc: 0.3669\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2448 - masked_acc: 0.3773\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man in a red shirt is swimming pool\n",
      "a person locking a light black man resting on the ocean\n",
      "\n",
      "100/100 [==============================] - 56s 566ms/step - loss: 3.2448 - masked_acc: 0.3773 - val_loss: 3.2404 - val_masked_acc: 0.3748\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2567 - masked_acc: 0.3763\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man with a yellow hat is riding a wave\n",
      "a man with a white and rope and a snowboarder ramp playfully leaping on her top\n",
      "\n",
      "100/100 [==============================] - 56s 556ms/step - loss: 3.2567 - masked_acc: 0.3763 - val_loss: 3.2369 - val_masked_acc: 0.3691\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.2140 - masked_acc: 0.3770\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man and a woman in the water\n",
      "a kayak in white is lays on their waves while holding a brown wave on a tractor\n",
      "\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 3.2140 - masked_acc: 0.3770 - val_loss: 3.1511 - val_masked_acc: 0.3795\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1863 - masked_acc: 0.3791\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a red shirt is walking through a wave\n",
      "the person in an orange dress next to face with a red and blue raft\n",
      "\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 3.1863 - masked_acc: 0.3791 - val_loss: 3.1529 - val_masked_acc: 0.3775\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1459 - masked_acc: 0.3903\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man in a red shirt is standing in the water\n",
      "a girl in the yellow surfboard in the water\n",
      "\n",
      "100/100 [==============================] - 60s 600ms/step - loss: 3.1459 - masked_acc: 0.3903 - val_loss: 3.2057 - val_masked_acc: 0.3725\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1814 - masked_acc: 0.3776\n",
      "\n",
      "a man in a yellow shirt is riding a wave\n",
      "a man in a red helmet is swimming pool\n",
      "a man reading a body of is down a man in the background\n",
      "\n",
      "100/100 [==============================] - 56s 560ms/step - loss: 3.1814 - masked_acc: 0.3776 - val_loss: 3.1900 - val_masked_acc: 0.3728\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.1480 - masked_acc: 0.3856\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a white is jumping into the water\n",
      "the man riding a young man in the ocean\n",
      "\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 3.1480 - masked_acc: 0.3856 - val_loss: 3.1435 - val_masked_acc: 0.3735\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0816 - masked_acc: 0.3921\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a girl is riding a wave\n",
      "a young man in white bathing clothing is pulled on a wave\n",
      "\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 3.0816 - masked_acc: 0.3921 - val_loss: 3.1071 - val_masked_acc: 0.3757\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0822 - masked_acc: 0.3888\n",
      "\n",
      "a man in a red shirt is swimming pool\n",
      "a man in a red shirt is swimming pool\n",
      "a girl with hat standing in the ocean\n",
      "\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 3.0822 - masked_acc: 0.3888 - val_loss: 3.1012 - val_masked_acc: 0.3816\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0460 - masked_acc: 0.3902\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a blue and yellow surfboard riding a wave\n",
      "the two men in the snow as his back has an inflatable headphones\n",
      "\n",
      "100/100 [==============================] - 54s 540ms/step - loss: 3.0460 - masked_acc: 0.3902 - val_loss: 3.0526 - val_masked_acc: 0.3779\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0300 - masked_acc: 0.3970\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man in a red shirt is riding a wave\n",
      "a surfer riding a surfer is wading in the surf\n",
      "\n",
      "100/100 [==============================] - 54s 544ms/step - loss: 3.0300 - masked_acc: 0.3970 - val_loss: 3.0881 - val_masked_acc: 0.3820\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0138 - masked_acc: 0.3939\n",
      "\n",
      "a surfer is riding a wave\n",
      "a surfer is surfing in the ocean\n",
      "a surfer in an orange cap gear races down\n",
      "\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 3.0138 - masked_acc: 0.3939 - val_loss: 3.1079 - val_masked_acc: 0.3754\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9856 - masked_acc: 0.3989\n",
      "\n",
      "a man in a red shirt is surfing a wave\n",
      "a yellow bird is riding a wave\n",
      "a man in a swimming wave\n",
      "\n",
      "100/100 [==============================] - 54s 546ms/step - loss: 2.9856 - masked_acc: 0.3989 - val_loss: 3.0674 - val_masked_acc: 0.3828\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 3.0140 - masked_acc: 0.3916\n",
      "\n",
      "a man in a red shirt is riding a wave\n",
      "a man in a yellow jacket is surfing a wave\n",
      "the man stands in midair around in the rapids\n",
      "\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 3.0140 - masked_acc: 0.3916 - val_loss: 3.0486 - val_masked_acc: 0.3805\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9806 - masked_acc: 0.3987\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a swimming wave\n",
      "the person wearing a white shirt is parked on a sunset in the ocean\n",
      "\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.9806 - masked_acc: 0.3987 - val_loss: 2.9982 - val_masked_acc: 0.3792\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9565 - masked_acc: 0.3999\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man with a wave in his mouth\n",
      "a surfer in the surfer is riding a surfboard\n",
      "\n",
      "100/100 [==============================] - 54s 541ms/step - loss: 2.9565 - masked_acc: 0.3999 - val_loss: 3.0243 - val_masked_acc: 0.3813\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9263 - masked_acc: 0.4053\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a red kayak is surfing in the water\n",
      "a surfer in a red jacket is pitches the wave\n",
      "\n",
      "100/100 [==============================] - 56s 566ms/step - loss: 2.9263 - masked_acc: 0.4053 - val_loss: 3.0055 - val_masked_acc: 0.3952\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8545 - masked_acc: 0.4123\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man in a red shirt and yellow surfboard\n",
      "the man is in the snowboard with his beige helmet is has toy\n",
      "\n",
      "100/100 [==============================] - 57s 570ms/step - loss: 2.8545 - masked_acc: 0.4123 - val_loss: 2.9954 - val_masked_acc: 0.3888\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.9002 - masked_acc: 0.4065\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a surfer is surfing on the water\n",
      "the surfer is being a surfer spot is surfing\n",
      "\n",
      "100/100 [==============================] - 54s 544ms/step - loss: 2.9002 - masked_acc: 0.4065 - val_loss: 2.9791 - val_masked_acc: 0.3874\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8911 - masked_acc: 0.4048\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man is surfing a wave in the water\n",
      "a man in a trunks enjoys the surfboard is surfing\n",
      "\n",
      "100/100 [==============================] - 54s 546ms/step - loss: 2.8911 - masked_acc: 0.4048 - val_loss: 3.0169 - val_masked_acc: 0.3858\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8796 - masked_acc: 0.4054\n",
      "\n",
      "a man in a red shirt and white surfboard\n",
      "a man in a white shirt is riding a wave\n",
      "a surfer in white gear is sitting on a wave\n",
      "\n",
      "100/100 [==============================] - 55s 556ms/step - loss: 2.8796 - masked_acc: 0.4054 - val_loss: 2.9552 - val_masked_acc: 0.3895\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8467 - masked_acc: 0.4115\n",
      "\n",
      "a man in a wetsuit is surfing on a wave\n",
      "a man in a yellow shirt is surfing\n",
      "a man is surfing on the waves into an orange bandanna is swimming\n",
      "\n",
      "100/100 [==============================] - 57s 567ms/step - loss: 2.8467 - masked_acc: 0.4115 - val_loss: 2.9332 - val_masked_acc: 0.3834\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8726 - masked_acc: 0.4067\n",
      "\n",
      "a man in a red wetsuit is surfing on a wave\n",
      "a surfer in a wetsuit is surfing in the water\n",
      "a wave spins in a water\n",
      "\n",
      "100/100 [==============================] - 66s 664ms/step - loss: 2.8726 - masked_acc: 0.4067 - val_loss: 2.9689 - val_masked_acc: 0.3966\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8565 - masked_acc: 0.4070\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man is surfing a wave\n",
      "a man is riding a wave\n",
      "\n",
      "100/100 [==============================] - 55s 549ms/step - loss: 2.8565 - masked_acc: 0.4070 - val_loss: 2.9643 - val_masked_acc: 0.3925\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8397 - masked_acc: 0.4112\n",
      "\n",
      "a man in a yellow kayak is surfing\n",
      "man in a yellow surfboard riding a surfboard\n",
      "a man is wearing a and black wetsuit on a surfboard\n",
      "\n",
      "100/100 [==============================] - 55s 547ms/step - loss: 2.8397 - masked_acc: 0.4112 - val_loss: 2.9063 - val_masked_acc: 0.3926\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.8136 - masked_acc: 0.4137\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man is riding a wave\n",
      "a man out a the wave is surfing and carrying a wave\n",
      "\n",
      "100/100 [==============================] - 54s 537ms/step - loss: 2.8136 - masked_acc: 0.4137 - val_loss: 2.9328 - val_masked_acc: 0.3931\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7379 - masked_acc: 0.4237\n",
      "\n",
      "a man in a yellow shirt is surfing\n",
      "a man in a yellow wave\n",
      "a surfer is running in a wave\n",
      "\n",
      "100/100 [==============================] - 53s 532ms/step - loss: 2.7379 - masked_acc: 0.4237 - val_loss: 2.9094 - val_masked_acc: 0.3907\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7829 - masked_acc: 0.4176\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a life jacket is surfing on a wave\n",
      "a man is surfing on a wave\n",
      "\n",
      "100/100 [==============================] - 54s 545ms/step - loss: 2.7829 - masked_acc: 0.4176 - val_loss: 2.9235 - val_masked_acc: 0.3918\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7740 - masked_acc: 0.4134\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a young boy is surfing a wave\n",
      "an wave during a white goggles\n",
      "\n",
      "100/100 [==============================] - 55s 548ms/step - loss: 2.7740 - masked_acc: 0.4134 - val_loss: 2.9474 - val_masked_acc: 0.3921\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7055 - masked_acc: 0.4233\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a white surfboard with a yellow surfboard\n",
      "a man wearing a black shirt surfing a wave on rough surfboard\n",
      "\n",
      "100/100 [==============================] - 55s 556ms/step - loss: 2.7055 - masked_acc: 0.4233 - val_loss: 2.8799 - val_masked_acc: 0.3981\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7344 - masked_acc: 0.4210\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "the man is surfing a wave\n",
      "a person riding out a wave\n",
      "\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 2.7344 - masked_acc: 0.4210 - val_loss: 2.9182 - val_masked_acc: 0.3972\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7234 - masked_acc: 0.4247\n",
      "\n",
      "a man in a red kayak is surfing\n",
      "a man in a red shirt is swimming in a wave\n",
      "a man stare into the water and are being pulled by his board\n",
      "\n",
      "100/100 [==============================] - 54s 538ms/step - loss: 2.7234 - masked_acc: 0.4247 - val_loss: 2.8888 - val_masked_acc: 0.3943\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7133 - masked_acc: 0.4194\n",
      "\n",
      "a man in a red wetsuit is surfing a wave\n",
      "a surfer is surfing a wave\n",
      "a young person sits in a pool while wearing a gold wave\n",
      "\n",
      "100/100 [==============================] - 56s 558ms/step - loss: 2.7133 - masked_acc: 0.4194 - val_loss: 2.9397 - val_masked_acc: 0.3897\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.7420 - masked_acc: 0.4222\n",
      "\n",
      "a man in a red wetsuit is surfing in the ocean\n",
      "a man in a red is surfing on a wave\n",
      "two boys are racing through headfirst overlooking a wave\n",
      "\n",
      "100/100 [==============================] - 56s 565ms/step - loss: 2.7420 - masked_acc: 0.4222 - val_loss: 2.8832 - val_masked_acc: 0.3934\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6901 - masked_acc: 0.4244\n",
      "\n",
      "a man in a red wetsuit is surfing\n",
      "a surfer in a red shirt and surfing\n",
      "a surfer\n",
      "\n",
      "100/100 [==============================] - 57s 574ms/step - loss: 2.6901 - masked_acc: 0.4244 - val_loss: 2.8717 - val_masked_acc: 0.4021\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6562 - masked_acc: 0.4271\n",
      "\n",
      "a man in a red wetsuit is surfing\n",
      "a man in a red surfboard riding a surfboard\n",
      "a couple in glasses is surfing on the ocean\n",
      "\n",
      "100/100 [==============================] - 54s 539ms/step - loss: 2.6562 - masked_acc: 0.4271 - val_loss: 2.9008 - val_masked_acc: 0.3940\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5858 - masked_acc: 0.4393\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man in a red surfboard riding a surfboard\n",
      "the man is two descent wave in the basketball\n",
      "\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 2.5858 - masked_acc: 0.4393 - val_loss: 2.8222 - val_masked_acc: 0.4043\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6306 - masked_acc: 0.4318\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man is playing in a swimming pool\n",
      "a person wearing a person riding on an orange wave\n",
      "\n",
      "100/100 [==============================] - 53s 533ms/step - loss: 2.6306 - masked_acc: 0.4318 - val_loss: 2.8566 - val_masked_acc: 0.4004\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6403 - masked_acc: 0.4312\n",
      "\n",
      "a man in a red shirt is surfing in the ocean\n",
      "a man in a red shirt is surfing on a surfboard\n",
      "man surfboard high in the air\n",
      "\n",
      "100/100 [==============================] - 54s 546ms/step - loss: 2.6403 - masked_acc: 0.4312 - val_loss: 2.9017 - val_masked_acc: 0.3980\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6366 - masked_acc: 0.4291\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a person in a surfer on a wave\n",
      "man in a wetsuit surfing on a white surfs\n",
      "\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 2.6366 - masked_acc: 0.4291 - val_loss: 2.9079 - val_masked_acc: 0.3966\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6087 - masked_acc: 0.4310\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man in a wetsuit in the ocean\n",
      "a person wearing craft flip in a green marching\n",
      "\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 2.6087 - masked_acc: 0.4310 - val_loss: 2.8705 - val_masked_acc: 0.3988\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6404 - masked_acc: 0.4286\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a red wetsuit is surfing in the ocean\n",
      "a man in a white surfs on the stomach\n",
      "\n",
      "100/100 [==============================] - 54s 542ms/step - loss: 2.6404 - masked_acc: 0.4286 - val_loss: 2.8087 - val_masked_acc: 0.3985\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6253 - masked_acc: 0.4281\n",
      "\n",
      "a man in a wetsuit is surfing\n",
      "a surfer is surfing on a wave\n",
      "a surfer on a dog flip splashing hand\n",
      "\n",
      "100/100 [==============================] - 53s 527ms/step - loss: 2.6253 - masked_acc: 0.4281 - val_loss: 2.8571 - val_masked_acc: 0.3930\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6202 - masked_acc: 0.4290\n",
      "\n",
      "a man in a red wetsuit is surfing\n",
      "a man in a wetsuit surfs\n",
      "a man in a big wave\n",
      "\n",
      "100/100 [==============================] - 53s 531ms/step - loss: 2.6202 - masked_acc: 0.4290 - val_loss: 2.8360 - val_masked_acc: 0.4106\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6313 - masked_acc: 0.4268\n",
      "\n",
      "a man in a red wetsuit is surfing\n",
      "a surfer rides a wave\n",
      "a man surfing a wave\n",
      "\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 2.6313 - masked_acc: 0.4268 - val_loss: 2.7719 - val_masked_acc: 0.4081\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5340 - masked_acc: 0.4431\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man in a red shirt is surfing\n",
      "a boy swimming in a hat giving a swimmer in the ocean\n",
      "\n",
      "100/100 [==============================] - 56s 564ms/step - loss: 2.5340 - masked_acc: 0.4431 - val_loss: 2.8541 - val_masked_acc: 0.3955\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5194 - masked_acc: 0.4416\n",
      "\n",
      "a man in a red shirt is surfing\n",
      "a man with a red shirt is surfing on a wave\n",
      "a surfer rides a board and wave on a wave\n",
      "\n",
      "100/100 [==============================] - 53s 530ms/step - loss: 2.5194 - masked_acc: 0.4416 - val_loss: 2.8175 - val_masked_acc: 0.4048\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5206 - masked_acc: 0.4415\n",
      "\n",
      "a man in a red shirt is surfing on a wave\n",
      "a man in a red shirt is surfing on a wave\n",
      "a cheerleader in a swimming pool\n",
      "\n",
      "100/100 [==============================] - 53s 535ms/step - loss: 2.5206 - masked_acc: 0.4415 - val_loss: 2.9012 - val_masked_acc: 0.4030\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5377 - masked_acc: 0.4396\n",
      "\n",
      "a man in a red surfboard is surfing\n",
      "a man in a red and white surfboard in the ocean\n",
      "a man surfing a wave\n",
      "\n",
      "100/100 [==============================] - 53s 528ms/step - loss: 2.5377 - masked_acc: 0.4396 - val_loss: 2.8328 - val_masked_acc: 0.4005\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.5161 - masked_acc: 0.4437\n",
      "\n",
      "a man in a red wetsuit is surfing\n",
      "a man in a red wetsuit surfs on a wave\n",
      "a man in a red yellow wetsuit rides a wave\n",
      "\n",
      "100/100 [==============================] - 53s 534ms/step - loss: 2.5161 - masked_acc: 0.4437 - val_loss: 2.8054 - val_masked_acc: 0.4032\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds.repeat(),\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=test_ds.repeat(),\n",
    "    validation_steps=20,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.preprocessing.string_lookup.StringLookup object at 0x000001774AEA8B10>, because it is not built.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 149). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/rspra/Desktop/Image_Captioning_Generator/model_best.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/rspra/Desktop/Image_Captioning_Generator/model_best.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/rspra/Desktop/Image_Captioning_Generator/model_best.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1770378ad90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Token')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man in a red wetsuit is surfing'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.simple_gen(image, temperature=0.0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/rspra/Desktop/Image_Captioning_Generator/flickr8k/Flicker8k_Dataset/27782020_4dab210360.jpg\n",
      "C:/Users/rspra/Desktop/Image_Captioning_Generator/Flickr8k_Dataset/Flicker8k_Dataset/12830823_87d2654e31.jpg\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk,Image\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "\n",
    "def choose_file():\n",
    "    filename = filedialog.askopenfilename(initialdir=os.getcwd(), title=\"Select image file\", filetypes=((\"JPG File\", \"*.jpg\"), (\"PNG file\", \"*.png\"), (\"All files\", \"*.\")))\n",
    "    entry1.delete(0, 'end')\n",
    "    entry1.insert(0,str(filename))\n",
    "    img = Image.open(filename)\n",
    "    img.thumbnail((550,500))\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    lbl.configure(image=img)\n",
    "    lbl.image = img\n",
    "    \n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Image Caption Generator Using Deep Learning\")\n",
    "root.geometry(\"650x650\")\n",
    "\n",
    "mylabel = Label(root, text = \" \", font=\"24\")\n",
    "\n",
    "def generateCaption(mylabel):\n",
    "    #filePath = entry1.get()\n",
    "    #fileNameArr = filePath.split(\"/\")\n",
    "    #file_name = fileNameArr[len(fileNameArr)-1]\n",
    "    file_name = entry1.get()\n",
    "    print(file_name)\n",
    "    image = load_image(file_name)\n",
    "    caption = model.simple_gen(image, temperature=0.0)\n",
    "\n",
    "    mylabel = mylabel.config(text=caption)\n",
    "    #mylabel.update()\n",
    "    \n",
    "\n",
    "frm = Frame(root)\n",
    "frm.pack(side=BOTTOM, padx=10, pady=10)\n",
    "\n",
    "\n",
    "lbl = Label(root)\n",
    "lbl.pack()\n",
    "\n",
    "entry1 = Entry(frm,width =90)\n",
    "\n",
    "button1 = Button(frm, text = \"Select Image\",command = choose_file, width=20)\n",
    "\n",
    "button2 = Button(frm, text=\"Generate Caption\", command= lambda : generateCaption(mylabel), width=20)\n",
    "\n",
    "\n",
    "entry1.pack()\n",
    "mylabel.pack()\n",
    "button1.pack(pady=5)\n",
    "button2.pack(padx=10, pady=10)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
